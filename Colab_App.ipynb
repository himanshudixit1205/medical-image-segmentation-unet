{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3-7M0gT_WuD"
      },
      "source": [
        "## Installation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "C8XJ3H8J_WHf"
      },
      "outputs": [],
      "source": [
        "pip install \"numpy>=1.23\" \"pandas>=1.5\" python-dateutil six \"matplotlib>=3.7\" \"seaborn>=0.12\" \"opencv-python>=4.8\" \"Pillow>=9.5\" \"scikit-image>=0.21\" \"nibabel>=5.1.0\" \"SimpleITK>=2.3.0\" \"scikit-learn>=1.3\" \"tqdm>=4.66\" \"tensorflow>=2.13\" \"keras>=2.13\" keras-unet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9Lfz2QX_QJl"
      },
      "source": [
        "## Utils File\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyUQENUd--xC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "import cv2\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# Image with Mask Image\n",
        "def plot_from_img_path(rows, columns, list_img_path, list_mask_path):\n",
        "    fig = plt.figure(figsize=(12,12))\n",
        "    rnge = rows * columns + 1\n",
        "\n",
        "    for i in range(1, rnge):\n",
        "        fig.add_subplot(rows, columns, i)\n",
        "        img_path = list_img_path[i]\n",
        "        mask_path = list_mask_path[i]\n",
        "\n",
        "        image = cv2.imread(img_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        mask = cv2.imread(mask_path)\n",
        "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        plt.imshow(image)\n",
        "        plt.imshow(mask, alpha=0.4)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Image and Mask Image side by sideimport matplotlib.pyplot as plt\n",
        "def show_img_mask_rows(n, list_img_path, list_mask_path):\n",
        "    fig = plt.figure(figsize=(6, 3 * n))\n",
        "\n",
        "    plot_idx = 1\n",
        "\n",
        "    for i in range(n):\n",
        "        img_path = list_img_path[i]\n",
        "        mask_path = list_mask_path[i]\n",
        "\n",
        "        image = cv2.imread(img_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        mask = cv2.imread(mask_path, 0)  # grayscale mask\n",
        "\n",
        "        # --- IMAGE ---\n",
        "        fig.add_subplot(n, 2, plot_idx)\n",
        "        plt.imshow(image)\n",
        "        plt.title(\"Image\")\n",
        "        plt.axis(\"off\")\n",
        "        plot_idx += 1\n",
        "\n",
        "        # --- MASK ---\n",
        "        fig.add_subplot(n, 2, plot_idx)\n",
        "        plt.imshow(mask, cmap='gray')\n",
        "        plt.title(\"Mask\")\n",
        "        plt.axis(\"off\")\n",
        "        plot_idx += 1\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# The Dice Coefficient (also called Dice Score or Dice Similarity Coefficient - DSC) is a metric used to measure overlap between two regions.\n",
        "def dice_coefficients(y_true, y_pred, smooth=100):\n",
        "    y_true_flatten = K.flatten(y_true)\n",
        "    y_pred_flatten = K.flatten(y_pred)\n",
        "\n",
        "    intersection = K.sum(y_true_flatten * y_pred_flatten)\n",
        "    union = K.sum(y_true_flatten) + K.sum(y_pred_flatten)\n",
        "    return (2 * intersection + smooth) / (union + smooth)\n",
        "\n",
        "def dice_coefficients_loss(y_true, y_pred, smooth=100):\n",
        "    return -dice_coefficients(y_true, y_pred, smooth) # Loss Metric\n",
        "\n",
        "# Intersection over Union (IoU) also known as the Jaccard Index or Jaccard similarity coefficient, is a fundamental metric used to measure the similarity and overlap between two sets. In computer vision, it is the standard for evaluating how accurately a model localizes objects.\n",
        "def iou(y_true_flatten, y_pred_flatten, smooth=100):\n",
        "    intersection = K.sum(y_true_flatten * y_pred_flatten)\n",
        "    add = K.sum(y_true_flatten + y_pred_flatten)\n",
        "    iou = (intersection + smooth) / (add - intersection + smooth) # Jaccard IOU\n",
        "    return iou\n",
        "\n",
        "# Jaccard distance is a measure of dissimilarity between two sets, derived directly from Jaccard similarity. While Jaccard similarity measures how much two sets overlap, Jaccard distance measures how different they are. It is defined as one minus the Jaccard similarity.\n",
        "def jaccard_distance(y_true, y_pred):\n",
        "    y_true_flatten = K.flatten(y_true)\n",
        "    y_pred_flatten = K.flatten(y_pred)\n",
        "\n",
        "    return -iou(y_true_flatten, y_pred_flatten) # Loss Metric\n",
        "\n",
        "\n",
        "## model.compile(optimizer=opt, loss=dice_coefficients_loss, metrics=['binary_accuracy', iou, dice_coefficients])\n",
        "\n",
        "# The Loss Function is the goal, and the Optimizer is the strategy to reach it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0D8mLVbqACDe"
      },
      "source": [
        "## UNet File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nirIouUQADor"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.models import Model, load_model, save_model\n",
        "from tensorflow.keras.layers import (\n",
        "    Input,\n",
        "    Activation,\n",
        "    BatchNormalization,\n",
        "    Dropout,\n",
        "    Lambda,\n",
        "    Conv2D,\n",
        "    Conv2DTranspose,\n",
        "    MaxPooling2D,\n",
        "    concatenate,\n",
        ")\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "\n",
        "def unet(input_size=(256,256,3)):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    ## Encoding Layer\n",
        "    # Layer 1\n",
        "    conv1 = Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\")(inputs)\n",
        "    bn1 = Activation(\"relu\")(conv1)\n",
        "    conv1 = Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\")(bn1)\n",
        "    bn1 = BatchNormalization(axis=3)(conv1)\n",
        "    bn1 = Activation(\"relu\")(bn1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(bn1)\n",
        "\n",
        "    # Layer 2\n",
        "    conv2 = Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\")(pool1)\n",
        "    bn2 = Activation(\"relu\")(conv2)\n",
        "    conv2 = Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\")(bn2)\n",
        "    bn2 = BatchNormalization(axis=3)(conv2)\n",
        "    bn2 = Activation(\"relu\")(bn2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(bn2)\n",
        "\n",
        "    # Layer 3\n",
        "    conv3 = Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\")(pool2)\n",
        "    bn3 = Activation(\"relu\")(conv3)\n",
        "    conv3 = Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\")(bn3)\n",
        "    bn3 = BatchNormalization(axis=3)(conv3)\n",
        "    bn3 = Activation(\"relu\")(bn3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(bn3)\n",
        "\n",
        "    # Layer 4\n",
        "    conv4 = Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\")(pool3)\n",
        "    bn4 = Activation(\"relu\")(conv4)\n",
        "    conv4 = Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\")(bn4)\n",
        "    bn4 = BatchNormalization(axis=3)(conv4)\n",
        "    bn4 = Activation(\"relu\")(bn4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(bn4)\n",
        "\n",
        "    # Layer 5\n",
        "    conv5 = Conv2D(filters=1024, kernel_size=(3, 3), padding=\"same\")(pool4)\n",
        "    bn5 = Activation(\"relu\")(conv5)\n",
        "    conv5 = Conv2D(filters=1024, kernel_size=(3, 3), padding=\"same\")(bn5)\n",
        "    bn5 = BatchNormalization(axis=3)(conv5)\n",
        "    bn5 = Activation(\"relu\")(bn5)\n",
        "\n",
        "    ## UpConvolutional\n",
        "    # Layer 6\n",
        "    up6 = concatenate([\n",
        "        Conv2DTranspose(512, kernel_size=(2,2), padding='same', strides=(2,2))(bn5), conv4], axis=3)\n",
        "    \"\"\" After every concatenation we again apply two consecutive regular convolutions so that the model can learn to assemble a more precise output \"\"\"\n",
        "    conv6 = Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\")(up6)\n",
        "    bn6 = Activation(\"relu\")(conv6)\n",
        "    conv6 = Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\")(bn6)\n",
        "    bn6 = BatchNormalization(axis=3)(conv6)\n",
        "    bn6 = Activation(\"relu\")(bn6)\n",
        "\n",
        "    # Layer 7\n",
        "    up7 = concatenate([\n",
        "        Conv2DTranspose(256, kernel_size=(2,2), padding='same', strides=(2,2))(bn6), conv3], axis=3)\n",
        "    conv7 = Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\")(up7)\n",
        "    bn7 = Activation(\"relu\")(conv7)\n",
        "    conv7= Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\")(bn7)\n",
        "    bn7 = BatchNormalization(axis=3)(conv7)\n",
        "    bn7 = Activation(\"relu\")(bn7)\n",
        "\n",
        "    # Layer 8\n",
        "    up8 = concatenate([\n",
        "        Conv2DTranspose(128, kernel_size=(2,2), padding='same', strides=(2,2))(bn7), conv2], axis=3)\n",
        "    conv8 = Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\")(up8)\n",
        "    bn8 = Activation(\"relu\")(conv8)\n",
        "    conv8 = Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\")(bn8)\n",
        "    bn8 = BatchNormalization(axis=3)(conv8)\n",
        "    bn8 = Activation(\"relu\")(bn8)\n",
        "\n",
        "    # Layer 9\n",
        "    up9 = concatenate([\n",
        "        Conv2DTranspose(64, kernel_size=(2,2), padding='same', strides=(2,2))(bn8), conv1], axis=3)\n",
        "    conv9 = Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\")(up9)\n",
        "    bn9 = Activation(\"relu\")(conv9)\n",
        "    conv9 = Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\")(bn9)\n",
        "    bn9 = BatchNormalization(axis=3)(conv9)\n",
        "    bn9 = Activation(\"relu\")(bn9)\n",
        "\n",
        "    ## Final Layer\n",
        "    # Layer 10\n",
        "    conv10 = Conv2D(filters=1, kernel_size=(1,1), activation='sigmoid')(bn9)\n",
        "\n",
        "    return Model(inputs=[inputs], outputs=[conv10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCDheHPFAM_y"
      },
      "source": [
        "## Main File"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLAK0uodPf_-"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZoAVByLAFKc"
      },
      "outputs": [],
      "source": [
        "## Imports\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "%matplotlib inline\n",
        "\n",
        "import cv2\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "from glob import glob\n",
        "from itertools import chain\n",
        "\n",
        "# from skimage.io import imread, imshow, concatenate_images\n",
        "# from skimage.transform import resize\n",
        "# from skimage.morphology import label\n",
        "# from skimage.color import rgb2gray\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.models import Model, load_model, save_model\n",
        "from tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yBqkSXUAXOm"
      },
      "outputs": [],
      "source": [
        "# Setting Size Parameters\n",
        "\n",
        "im_width = 256\n",
        "im_height = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gn7PvVX_PZLD"
      },
      "source": [
        "## Mount Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13_pgGPUBLn7"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "from glob import glob\n",
        "import os\n",
        "\n",
        "# 1. Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Updated path for Google Colab\n",
        "mask_files = glob(r'/content/drive/MyDrive/Colab Notebooks/Medical Computer Vision/datasets/kaggle_3m/*/*_mask*')\n",
        "\n",
        "print(f\"Found {len(mask_files)} mask files.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxeKdzFxBG3x"
      },
      "outputs": [],
      "source": [
        "image_filenames_train = []\n",
        "\n",
        "for i in mask_files:\n",
        "    image_filenames_train.append(i.replace('_mask',''))\n",
        "\n",
        "print(image_filenames_train[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzD97yBlAeUs"
      },
      "outputs": [],
      "source": [
        "len(image_filenames_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPwdwStAPW57"
      },
      "source": [
        "## Plot Images and Mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Y0eggSSAiWT"
      },
      "outputs": [],
      "source": [
        "row = 3\n",
        "column = 3\n",
        "\n",
        "plot_from_img_path(row, column, image_filenames_train, mask_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TS5DPZ2cPjXx"
      },
      "outputs": [],
      "source": [
        "show_img_mask_rows(3, image_filenames_train, mask_files)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJnAItQZPsvC"
      },
      "source": [
        "## DataFrame and Train_Test_Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsJyi69ePpS6"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(data= {\n",
        "    'image_filenames_train':image_filenames_train,\n",
        "    'mask':mask_files\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yM-zXGcTPwhy"
      },
      "outputs": [],
      "source": [
        "# Train and Test Split\n",
        "df_train, df_test = train_test_split(df, test_size=0.1)\n",
        "\n",
        "# Train and VAl Split\n",
        "df_train, df_val = train_test_split(df_train, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUjZ99J0Px0R"
      },
      "outputs": [],
      "source": [
        "df_train.shape, df_val.shape, df_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OjkJxPnP0qc"
      },
      "source": [
        "## Data Generator : Passing my data in batch to Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zz199fhBPzPr"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# After Mask Normalization value is less than or equal to 0.5. Then we will skip that mask.\n",
        "def normalize_and_diagnose(img,mask):\n",
        "    img = img / 255\n",
        "    mask = mask / 255\n",
        "    mask[mask > 0.5] = 1 # Its Tumor\n",
        "    mask[mask <= 0.5] = 0 # Not a Tumor\n",
        "    return (img, mask)\n",
        "\n",
        "# Referring Code from : https://github.com/zhixuhao/unet/blob/master/data.py\n",
        "# Using 'train_generator' for Load and process data in batches while training, instead of loading everything into memory.\n",
        "def train_generator(\n",
        "    data_frame,\n",
        "    batch_size,\n",
        "    augmentation_dict,\n",
        "    image_color_mode=\"rgb\",\n",
        "    mask_color_mode=\"grayscale\",\n",
        "    image_save_prefix=\"image\",\n",
        "    mask_save_prefix=\"mask\",\n",
        "    save_to_dir=None,\n",
        "    target_size=(256, 256),\n",
        "    seed=1,\n",
        "):\n",
        "    \"\"\"\n",
        "    can generate image and mask at the same time use the same seed for\n",
        "    image_datagen and mask_datagen to ensure the transformation for image\n",
        "    and mask is the same if you want to visualize the results of generator,\n",
        "    set save_to_dir = \"your path\"\n",
        "    \"\"\"\n",
        "    image_datagen = ImageDataGenerator(**augmentation_dict)\n",
        "    mask_datagen = ImageDataGenerator(**augmentation_dict)\n",
        "\n",
        "    image_generator = image_datagen.flow_from_dataframe(\n",
        "        data_frame,                    # Pandas DataFrame containing file paths\n",
        "        x_col=\"image_filenames_train\",# Column name with image file paths\n",
        "        class_mode=None,              # No labels returned (augmentation only)\n",
        "        color_mode=image_color_mode,  # 'rgb' or 'grayscale' image mode\n",
        "        target_size=target_size,      # Resize images to (height, width)\n",
        "        batch_size=batch_size,        # Images per batch\n",
        "        save_to_dir=save_to_dir,      # Directory to save augmented images\n",
        "        save_prefix=image_save_prefix,# Prefix for saved filenames\n",
        "        seed=seed,                    # Random seed for reproducibility\n",
        "    )\n",
        "\n",
        "\n",
        "    mask_generator = mask_datagen.flow_from_dataframe(\n",
        "        data_frame,\n",
        "        x_col=\"mask\",\n",
        "        class_mode=None,\n",
        "        color_mode=mask_color_mode,\n",
        "        target_size=target_size,\n",
        "        batch_size=batch_size,\n",
        "        save_to_dir=save_to_dir,\n",
        "        save_prefix=mask_save_prefix,\n",
        "        seed=seed,\n",
        "    )\n",
        "\n",
        "    train_gen = zip(image_generator, mask_generator)\n",
        "\n",
        "    # Final return Tuple after image Normalization and Diagnostics\n",
        "    for (img, mask) in train_gen:\n",
        "        img, mask = normalize_and_diagnose(img, mask)\n",
        "        yield (img, mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lb3r7O3HP6cC"
      },
      "outputs": [],
      "source": [
        "# HyperParameters\n",
        "\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 1e-4\n",
        "SMOOTH = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yka-CFuIP-By"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers.legacy import Adam # Using Legacy 'Adam' Optimizer for 'decay'.\n",
        "\n",
        "train_generator_param = dict(\n",
        "    rotation_range=0.2,          # Randomly rotate images up to ±20% degrees\n",
        "    width_shift_range=0.05,      # Random horizontal shift up to 5% of image width\n",
        "    height_shift_range=0.05,     # Random vertical shift up to 5% of image height\n",
        "    shear_range=0.05,            # Apply small shear transformations\n",
        "    zoom_range=0.05,             # Random zoom in/out up to 5%\n",
        "    horizontal_flip=True,        # Randomly flip images horizontally\n",
        "    fill_mode='nearest'          # Fill missing pixels after transform using nearest values\n",
        ")\n",
        "\n",
        "train_gen = train_generator(\n",
        "    df_train,                    # DataFrame containing training image paths and labels\n",
        "    BATCH_SIZE,                 # Number of samples per training batch\n",
        "    train_generator_param,      # Augmentation configuration dictionary\n",
        "    target_size=(im_height, im_width)  # Resize images to model input size\n",
        ")\n",
        "\n",
        "# Not applying Augmentation on Test Set.\n",
        "test_gen = train_generator(df_test,\n",
        "                            BATCH_SIZE,\n",
        "                            dict(), # Empty dict = no augmentation\n",
        "                            target_size=(im_height, im_width))\n",
        "\n",
        "model = unet(input_size=(im_height, im_width, 3)) # Input shape (Height, Width, RGB channels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mM7wEHtgQAZS"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "\n",
        "# Decay rate gradually reduces the learning rate during training so the model \"Learns fast at the beginning. Fine-tunes carefully later\".\n",
        "\n",
        "# Learning rate schedule (modern replacement for decay)\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=LEARNING_RATE,\n",
        "    decay_steps= 1000,           # Safe default, prevents extremely fast decay\n",
        "    decay_rate= LEARNING_RATE / EPOCHS ,\n",
        "    staircase= True\n",
        ")\n",
        "\n",
        "optimizer = Adam(\n",
        "    learning_rate=lr_schedule,  # Replaces deprecated lr + decay\n",
        "    beta_1=0.9,                 # Explicit to avoid legacy behavior differences\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-7,               # Required in Keras 3 (None can cause issues)\n",
        "    amsgrad=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuM9n30SQKj1",
        "outputId": "d25397cc-29af-4544-cf87-975b992ae036"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2827 validated image filenames.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 25 invalid image filename(s) in x_col=\"image_filenames_train\". These filename(s) will be ignored.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2852 validated image filenames.\n",
            "\u001b[1m85/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1:45\u001b[0m 26s/step - binary_accuracy: 0.7804 - dice_coefficients: 0.0495 - iou: 0.0256 - loss: -0.0495"
          ]
        }
      ],
      "source": [
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,        # Optimization algorithm\n",
        "    loss=dice_coefficients_loss,# Loss function (Dice loss for segmentation)\n",
        "    metrics=[\n",
        "        'binary_accuracy',      # Pixel-wise classification accuracy\n",
        "        iou,                    # Intersection over Union metric\n",
        "        dice_coefficients       # Dice similarity score\n",
        "    ]\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\n",
        "        'unet.keras',            # File path to save best model\n",
        "        verbose=1,              # Print message when saving\n",
        "        save_best_only=True     # Save only when validation improves\n",
        "    )\n",
        "]\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    train_gen,                                 # Training data generator\n",
        "    steps_per_epoch=len(df_train) // BATCH_SIZE,# Batches per epoch\n",
        "    epochs=EPOCHS,                             # Total number of training epochs\n",
        "    callbacks=callbacks,                       # List of callbacks\n",
        "    validation_data=test_gen,                  # Validation generator\n",
        "    validation_steps=len(df_test) // BATCH_SIZE# Validation batches per epoch\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdyWcUgFQPcV"
      },
      "outputs": [],
      "source": [
        "# Check History objects\n",
        "\n",
        "import pprint # Printing objects\n",
        "\n",
        "pprint.pprint(history.history)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dO1L9oBTQSD0"
      },
      "outputs": [],
      "source": [
        "history_post_training = history.history\n",
        "train_dice_coeff_list = history_post_training['dice_coefficients']\n",
        "test_dice_coeff_list = history_post_training['val_dice_coefficients']\n",
        "\n",
        "train_jaccard_list = history_post_training['iou']\n",
        "test_jaccard_list = history_post_training['val_iou']\n",
        "\n",
        "train_loss_list = history_post_training['loss']\n",
        "test_loss_list = history_post_training['val_loss']\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(test_loss_list, 'b-')\n",
        "plt.plot(train_loss_list, 'r-')\n",
        "plt.xlabel('iterations')\n",
        "plt.ylabel('loss')\n",
        "plt.title('loss graph', fontsize=12)\n",
        "\n",
        "plt.figure(2)\n",
        "plt.plot(train_dice_coeff_list, 'b-')\n",
        "plt.plot(test_dice_coeff_list, 'r-')\n",
        "plt.xlabel('iterations')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('accuracy graph', fontsize=12)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ond6xDv6QUDp"
      },
      "outputs": [],
      "source": [
        "# Load Previouly Trained Model\n",
        "\n",
        "model = load_model(\"unet.hdf5\", custom_objects = {\"dice_coefficient_loss\": dice_coefficients_loss, 'iou': iou,\n",
        "                                                 \"dice_coefficient\" : dice_coefficients})\n",
        "\n",
        "test_gen = train_generator(df_test, BATCH_SIZE, dict(), target_size = (im_height, im_width))\n",
        "\n",
        "results = model.evaluate(test_gen, steps = len(df_test)/BATCH_SIZE)\n",
        "\n",
        "print(\"TEST LOSS\", results[0])\n",
        "print(\"TEST IOU\", results[1])\n",
        "print(\"TEST DICE COEFFICIENT\", results[2])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZjyZE6EQZgA"
      },
      "source": [
        "## Plotting Predicted Mask Segmentations Results from Test Image Set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sqrzc4RcQXbw"
      },
      "outputs": [],
      "source": [
        "for i in range(20):\n",
        "    index = np.random.randint(1, len(df_test.index))\n",
        "    img = cv2.imread(df_test['image_filename_train'].iloc[index]) # Original Image NOt Mask\n",
        "    img = cv2.resize(img, (im_height, im_width))\n",
        "    img = img / 255\n",
        "    #print(img.shape) (256, 256, 3)\n",
        "    img = img[np.newaxis, :, :, :] # 3d array will become 4d array\n",
        "    #print(img.shape) (1, 256, 256, 3)\n",
        "    predicted_img = model.predict(img)\n",
        "\n",
        "    plt.figure(figsize=(12,12))\n",
        "    # 3 columns original image, mask, predicted image\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.imshow(np.squeeze(img))\n",
        "    plt.title('Original IMage')\n",
        "\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.imshow(np.squeeze(cv2.imread(df_test['mask'].iloc[index])))\n",
        "    plt.title(\"Mask Image\")\n",
        "\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.imshow(np.squeeze(predicted_img) > 0.5) # Checking Probabilities\n",
        "    plt.title('Predicted Image')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_Q8a9ouQbcR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "runtime_attributes": {
        "runtime_version": "2026.01"
      }
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
